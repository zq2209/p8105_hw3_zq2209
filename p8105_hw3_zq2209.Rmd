---
title: "p8105_hw3_zq2209"
author: "Zining Qi"
date: "2022-10-12"
output: github_document
---
```{r}
library(tidyverse)
library(ggridges)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


# Problem 1
```{r}
library(p8105.datasets)
data("instacart")
```

```{r}
instacart = 
  instacart %>% 
  as_tibble(instacart)
```

```{r}
# How many aisles are there, and which aisles are the most items ordered from?
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

```{r}
# Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle",
       x = "Aisle",
       y = "Number of items") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

```{r}
# Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(desc(n)) %>%
  knitr::kable()
```

```{r}
# Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  ) %>% 
  knitr::kable(digits = 2)
```



# Problem 2
```{r}
accel = read_csv("./dataset/accel_data.csv")
```

```{r}
# Cleaning, tidying, and wrangling data
accel_data = accel %>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  mutate(Weekday_Weekend = ifelse(day %in% c("Saturday", "Sunday"), "Weekend", "Weekday")) %>% 
  group_by(week, day_id) %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity_time", 
    names_prefix = "activity_",
    values_to = "activity_amount")

nrow(accel_data)
ncol(accel_data)

accel_data
```

After tidying,, cleaning and adding variables, there are 50400 rows, and 6 columns. The variables are week, day_id, day, weekday vs weekend, activity time, and activity amount. Activity time is the minute if activity in that day, and activity amount is the count of that activity in that minute.Weekday vs Weekend is whether that day is weekday or weekend.


```{r}
# Total activity over the day
total_activity = accel_data %>% 
  group_by(week, day, day_id) %>% 
  summarize(total = sum(activity_amount)) %>% 
  knitr::kable()
total_activity

total_activity_plot = accel_data %>% 
  group_by(week, day, day_id) %>% 
  summarize(total = sum(activity_amount)) %>% 
  ggplot(aes(x = day, y = total, color = week)) +
  geom_point()
total_activity_plot
```

As shown in the plot, The total amount of activities in Friday, Monday, Saturday, and Sunday are more spread. In Thursday, Tuesday, and Wednesday, total activities are tighter. And in Saturday, it has lowest activity amount.

```{r}
# Activity over the course of the 24 hours
activity_of_day = accel_data %>% 
  mutate(activity_amount = round(activity_amount,0),
         activity_time = as.integer(activity_time)) %>% 
  ggplot(aes(x = activity_time, y = activity_amount, color = day)) +
  geom_smooth(se = FALSE) +
  scale_x_continuous(
    breaks = c(0, 240, 480, 720, 960, 1200, 1440),
    labels = c("12:00 AM", "4:00 AM", "8:00 AM", "12:00 PM", "4:00 PM", "8:00 PM", "12:00 PM")
  ) +
  labs(
    title = "Activity over the course of the 24 hours",
    x = "Time of Activity",
    y = "Amount of Activity"
  )

activity_of_day
```

According to the graph, activity amout during 12am to 4am is really low, almost 0. And the amount start increasing from 4am. The amount from 8am to 6pm are stay approximate consistent, except for Thursday. There is a peak in 11am on Thursday. And from 8pm to 10pm, the activity amount increase, especially on Friday, the amount is the highest. From 11pm, it start decreasing.



# Problem 3
```{r}
library(p8105.datasets)
data("ny_noaa")
```

```{r}
ny_noaa %>% 
  janitor::clean_names() %>% 
  summary()

nrow(ny_noaa)
ncol(ny_noaa)
```

There are 2595176 rows and 7 columns. The dataset contains 7 variables, which are station id, date, prcp:Precipitation (tenths of mm), snow:Snowfall (mm), snwd:Snow depth (mm), tmax:Maximum temperature (tenths of degrees C), tmin:Minimum temperature (tenths of degrees C). prcp, tmax, tmin are measured in tenth, so it will be divided by 10. But for prcp, snow, and snwd, tmax, and tmin, there are many NA, shown in summary table. NAs have to be dropped during calculation later.


```{r}
# Do some data cleaning
noaa = ny_noaa %>% 
  janitor::clean_names() %>% 
  separate(col = date, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(tmax = as.numeric(tmax),
         tmin = as.numeric(tmin),
         year = as.numeric(year),
         month = as.numeric(month),
         day = as.numeric(day),
         month = month.abb[month],
         tmax = tmax / 10,
         tmin = tmin / 10,
         prcp = prcp / 10
         ) %>% 
  select(year, month, day, everything())

noaa  
```



```{r}
most_observed_snow = noaa %>% 
  group_by(snow) %>% 
  drop_na() %>% 
  summarize(n_obs = n()) %>%
  arrange(desc(n_obs))

most_observed_snow
```


```{r}
mean_tmax = noaa %>% 
  filter(month %in% c("Jan", "Jul")) %>% 
  group_by(year, month) %>% 
  summarize(mean_tmax = mean(tmax, na.rm = TRUE)) %>% 
  ggplot(aes(x = year, y = mean_tmax)) +
  geom_point(alpha = .5) +
  geom_smooth(se = TRUE) +
  facet_grid(. ~ month) +
  labs(title = "Average max temperature across year",
         x = "year",
         y = "Average max temperature")

mean_tmax
```
  

```{r}
tmax_vs_tmin = noaa %>% 
  drop_na() %>% 
  ggplot(aes(x = tmin, y = tmax)) +
  geom_smooth() +
  labs(title = "tmax vs. tmin",
         x = "Min temperature",
         y = "Max temperature")

tmax_vs_tmin  
```

```{r}
snowfall = noaa %>% 
  drop_na() %>% 
  filter(snow > 0) %>% 
  filter(snow < 100) %>% 
  mutate(year = as.factor(year)) %>% 
  ggplot(aes(x = snow, y = year, fill = year)) +
  geom_density_ridges(scale = 0.85) +
  labs(title = "Snowfall distribution by year",
         x = "Snowfall",
         y = "Year")
snowfall
```



