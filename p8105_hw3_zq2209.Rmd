---
title: "p8105_hw3_zq2209"
author: "Zining Qi"
date: "2022-10-12"
output: github_document
---
```{r}
library(tidyverse)
library(ggridges)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


# Problem 1
```{r}
library(p8105.datasets)
data("instacart")
```

```{r}
instacart = 
  instacart %>% 
  as_tibble(instacart)
```

```{r}
# How many aisles are there, and which aisles are the most items ordered from?
instacart %>% 
  count(aisle) %>% 
  arrange(desc(n))
```

```{r}
# Make a plot that shows the number of items ordered in each aisle, limiting this to aisles with more than 10000 items ordered
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle",
       x = "Aisle",
       y = "Number of items") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

```{r}
# Make a table showing the three most popular items in each of the aisles “baking ingredients”, “dog food care”, and “packaged vegetables fruits”
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(desc(n)) %>%
  knitr::kable()
```

```{r}
# Make a table showing the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>% 
  pivot_wider(
    names_from = order_dow,
    values_from = mean_hour
  ) %>% 
  knitr::kable(digits = 2)
```



# Problem 2
```{r}
accel = read_csv("/Users/qizining/Desktop/p8105_hw3_zq2209/accel_data.csv")
```

```{r}
# Tidy
accel_data = accel %>% 
  janitor::clean_names() %>% 
  drop_na() %>% 
  mutate(Weekday_Weekend = ifelse(day %in% c("Saturday", "Sunday"), "Weekend", "Weekday")) %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity_time", 
    names_prefix = "activity_",
    values_to = "activity_amount")

nrow(accel_data)
ncol(accel_data)

accel_data
```

```{r}
# total activity over the day
total_activity = accel_data %>% 
  group_by(week, day, day_id) %>% 
  summarize(total = sum(activity_amount)) %>% 
  knitr::kable()

total_activity
```

```{r}
# activity over the course of the 24 hours
activity_of_day = accel_data %>% 
  mutate(activity_amount = round(activity_amount,0),
         activity_time = as.integer(activity_time)) %>% 
  ggplot(aes(x = activity_time, y = activity_amount, color = day)) +
  geom_smooth(se = FALSE) +
  scale_x_continuous(
    breaks = c(0, 240, 480, 720, 960, 1200, 1440),
    labels = c("12:00 AM", "4:00 AM", "8:00 AM", "12:00 PM", "4:00 PM", "8:00 PM", "12:00 PM")
  ) +
  labs(
    title = "Activity over the course of the 24 hours",
    x = "Time",
    y = "Activity Amount"
  )

activity_of_day
```


# Problem 3
```{r}
library(p8105.datasets)
data("ny_noaa")
```

```{r}
ny_noaa %>% 
  janitor::clean_names() %>% 
  summary()

nrow(ny_noaa)
ncol(ny_noaa)
```

There are 2595176 rows and 7 columns. The dataset contains 7 variables, which are id, date, prcp, snow, snwd(), tmax(), tmin(). prcp, snow, snwd are measured in mm. tmax and tmin are measured in tenths of degrees. But for prcp, snow, and snwd, there are many NA. 


```{r}
noaa = ny_noaa %>% 
  janitor::clean_names() %>% 
  separate(col = date, into = c("year", "month", "day"), sep = "-") %>% 
  mutate(tmax = as.numeric(tmax),
         tmin = as.numeric(tmin),
         year = as.numeric(year),
         month = as.numeric(month),
         day = as.numeric(day),
         month = month.abb[month],
         tmax = tmax / 10,
         tmin = tmin / 10,
         prcp = prcp / 10
         ) 

noaa  
```

```{r}
most_observed_snow = noaa %>% 
  group_by(snow) %>% 
  drop_na() %>% 
  summarize(n_obs = n()) %>%
  arrange(desc(n_obs))

most_observed_snow
```


```{r}
mean_tmax = noaa %>% 
  filter(month %in% c("Jan", "Jul")) %>% 
  group_by(year, month) %>% 
  summarize(mean_tmax = mean(tmax, na.rm = TRUE)) %>% 
  ggplot(aes(x = year, y = mean_tmax)) +
  geom_point(alpha = .5) +
  geom_smooth(se = TRUE) +
  facet_grid(. ~ month) +
  labs(title = "Average max temperature across year",
         x = "year",
         y = "Average max temperature")

mean_tmax
```
  

```{r}
tmax_vs_tmin = noaa %>% 
  drop_na() %>% 
  ggplot(aes(x = tmin, y = tmax)) +
  geom_smooth() +
  labs(title = "tmax vs. tmin",
         x = "Min temperature",
         y = "Max temperature")

tmax_vs_tmin  
```

```{r}
snowfall = noaa %>% 
  drop_na() %>% 
  filter(snow > 0) %>% 
  filter(snow < 100) %>% 
  mutate(year = as.factor(year)) %>% 
  ggplot(aes(x = snow, y = year, fill = year)) +
  geom_density_ridges(scale = 0.85) +
  labs(title = "Snowfall distribution by year",
         x = "Snowfall",
         y = "Year")
snowfall
```



